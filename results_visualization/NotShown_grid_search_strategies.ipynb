{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "files = glob.glob('./server_results/grid_search_strategies/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_aggregate(df):\n",
    "\n",
    "\n",
    "    # print(df['method_strategy'])\n",
    "\n",
    "    df_grouped = df.groupby(['method_strategy'])['mrr'].agg(\n",
    "        ['median', 'mean', 'min', 'max', 'std']).reset_index()\n",
    "\n",
    "    df_grouped = df_grouped.sort_values(by='mean', ascending=False)\n",
    "\n",
    "    print(df_grouped.head(10).to_string())\n",
    "    return df_grouped\n",
    "\n",
    "\n",
    "def plot_boxplot(df, x, y, datasetname):\n",
    "    # Create the figure and axes with a narrower width (e.g., 8)\n",
    "    fig, ax = plt.subplots(figsize=(6.5, 2))  # Make the plot narrower by reducing the width\n",
    "\n",
    "\n",
    "    df = df[df[x].str.contains('strsim:-1')]\n",
    "\n",
    "    print(df[x].unique())\n",
    "    replacement_dict = {\n",
    "        'strsim:-1_emb:1_eq:-1': 'EMB',\n",
    "        'strsim:-1_emb:-1_eq:1': 'EQ',\n",
    "        'strsim:-1_emb:1_eq:2': 'EMB, then EQ',\n",
    "        'strsim:-1_emb:2_eq:1': 'EQ, then EMB',\n",
    "    }\n",
    "\n",
    "    df[x] = df[x].replace(replacement_dict)\n",
    "\n",
    "\n",
    "    # Compute the average mean of y for each x and use this as the order\n",
    "    order = df.groupby(x)[y].mean().sort_values(ascending=False).index\n",
    "\n",
    "    # Plot the boxplot with narrower boxes\n",
    "    sns.boxplot(\n",
    "        data=df,\n",
    "        x=x,  # Plot data along the x-axis\n",
    "        y=y,  # Plot distribution of 'y' variable\n",
    "        ax=ax,\n",
    "        palette=sns.color_palette(\"Set2\"),  # Use a better palette\n",
    "        width=0.5,  # Adjust box width (default is usually around 0.8)\n",
    "        order=order  # Use the computed order\n",
    "         , showfliers=False\n",
    "    )\n",
    "    \n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_xticklabels(ax.get_xticklabels())\n",
    "    ax.set_ylabel(y.upper(), fontsize=12)\n",
    "    # ax.set_title(f'{y} Distribution for {x} in {datasetname}', fontsize=14)\n",
    "    \n",
    "    # Customize ticks\n",
    "    ax.tick_params(axis='x', labelsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "    sns.despine()\n",
    "\n",
    "    # Save the figure as a high-resolution PDF\n",
    "    fig.savefig(\"figures/grid_search_strategies.pdf\", format='pdf', dpi=300)\n",
    "    \n",
    "    # Adjust layout to ensure everything fits\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = []\n",
    "for file in files:\n",
    "    datasetname = file.split('_')[0]\n",
    "    datasetname = file.split('/')[-1].split('_')[0]\n",
    "    print(f'Analyzing {datasetname}')\n",
    "    df = pd.read_csv(file)\n",
    "    # print(df.head())\n",
    "\n",
    "\n",
    "    df['strategy'] = (\n",
    "        'strsim:' + df['strsim'].astype(str) +\n",
    "        '_emb:' + df['emebedding'].astype(str) +\n",
    "        '_eq:' + df['equal'].astype(str)\n",
    "    )\n",
    "\n",
    "    all_dfs.append(df)\n",
    "\n",
    "\n",
    "    plot_boxplot(df, 'strategy', 'mrr', datasetname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_dfs \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(all_dfs)\n\u001b[1;32m      2\u001b[0m plot_boxplot(all_dfs, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrategy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmrr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_datasets\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:380\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    378\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    381\u001b[0m     objs,\n\u001b[1;32m    382\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m    383\u001b[0m     ignore_index\u001b[38;5;241m=\u001b[39mignore_index,\n\u001b[1;32m    384\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[1;32m    385\u001b[0m     keys\u001b[38;5;241m=\u001b[39mkeys,\n\u001b[1;32m    386\u001b[0m     levels\u001b[38;5;241m=\u001b[39mlevels,\n\u001b[1;32m    387\u001b[0m     names\u001b[38;5;241m=\u001b[39mnames,\n\u001b[1;32m    388\u001b[0m     verify_integrity\u001b[38;5;241m=\u001b[39mverify_integrity,\n\u001b[1;32m    389\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    390\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    391\u001b[0m )\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:443\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 443\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clean_keys_and_objs(objs, keys)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    446\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/reshape/concat.py:505\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    502\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     objs_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs_list))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "all_dfs = pd.concat(all_dfs)\n",
    "plot_boxplot(all_dfs, 'strategy', 'mrr', 'all_datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregates\n",
      "Analyzing GDC\n",
      "          method_strategy    median      mean       min       max       std\n",
      "2    strsim:-1_emb:1_eq:2  0.641667  0.617717  0.433333  0.754762  0.117123\n",
      "1   strsim:-1_emb:1_eq:-1  0.641667  0.616568  0.433333  0.790476  0.118292\n",
      "3    strsim:-1_emb:2_eq:1  0.641667  0.616568  0.433333  0.790476  0.118292\n",
      "7     strsim:1_emb:2_eq:3  0.641667  0.608574  0.433333  0.734848  0.109864\n",
      "6    strsim:1_emb:2_eq:-1  0.602339  0.600522  0.433333  0.754464  0.108839\n",
      "8     strsim:1_emb:3_eq:2  0.602339  0.600522  0.433333  0.754464  0.108839\n",
      "12    strsim:2_emb:3_eq:1  0.602339  0.600522  0.433333  0.754464  0.108839\n",
      "11    strsim:2_emb:1_eq:3  0.555511  0.563358  0.393981  0.702922  0.115591\n",
      "10   strsim:2_emb:1_eq:-1  0.555511  0.521614  0.310648  0.702922  0.141554\n",
      "13    strsim:3_emb:1_eq:2  0.555511  0.521614  0.310648  0.702922  0.141554\n",
      "Analyzing GDC\n",
      "          method_strategy    median      mean       min       max       std\n",
      "2    strsim:-1_emb:1_eq:2  0.625000  0.598535  0.465432  0.711988  0.090109\n",
      "7     strsim:1_emb:2_eq:3  0.625000  0.588716  0.465432  0.709092  0.088436\n",
      "1   strsim:-1_emb:1_eq:-1  0.540000  0.581452  0.437654  0.706169  0.094747\n",
      "3    strsim:-1_emb:2_eq:1  0.540000  0.572433  0.437654  0.698247  0.085194\n",
      "6    strsim:1_emb:2_eq:-1  0.525251  0.571528  0.437654  0.703283  0.091129\n",
      "12    strsim:2_emb:3_eq:1  0.525251  0.571528  0.437654  0.703283  0.091129\n",
      "8     strsim:1_emb:3_eq:2  0.525251  0.562509  0.437654  0.657828  0.080105\n",
      "11    strsim:2_emb:1_eq:3  0.514474  0.510574  0.375231  0.625000  0.072669\n",
      "10   strsim:2_emb:1_eq:-1  0.463041  0.443676  0.291898  0.531899  0.084352\n",
      "13    strsim:3_emb:1_eq:2  0.463041  0.443676  0.291898  0.531899  0.084352\n",
      "Analyzing musicians\n",
      "          method_strategy  median      mean       min  max       std\n",
      "1   strsim:-1_emb:1_eq:-1  0.9750  0.945833  0.833333  1.0  0.078617\n",
      "2    strsim:-1_emb:1_eq:2  0.9750  0.945833  0.833333  1.0  0.078617\n",
      "3    strsim:-1_emb:2_eq:1  0.9750  0.945833  0.833333  1.0  0.078617\n",
      "6    strsim:1_emb:2_eq:-1  0.9750  0.945833  0.833333  1.0  0.078617\n",
      "7     strsim:1_emb:2_eq:3  0.9750  0.945833  0.833333  1.0  0.078617\n",
      "8     strsim:1_emb:3_eq:2  0.9750  0.945833  0.833333  1.0  0.078617\n",
      "12    strsim:2_emb:3_eq:1  0.9750  0.945833  0.833333  1.0  0.078617\n",
      "10   strsim:2_emb:1_eq:-1  0.8125  0.845833  0.758333  1.0  0.107260\n",
      "11    strsim:2_emb:1_eq:3  0.8125  0.845833  0.758333  1.0  0.107260\n",
      "13    strsim:3_emb:1_eq:2  0.8125  0.845833  0.758333  1.0  0.107260\n",
      "Analyzing Magellan\n",
      "          method_strategy  median  mean  min  max  std\n",
      "0   strsim:-1_emb:-1_eq:1     1.0   1.0  1.0  1.0  0.0\n",
      "2    strsim:-1_emb:1_eq:2     1.0   1.0  1.0  1.0  0.0\n",
      "4   strsim:1_emb:-1_eq:-1     1.0   1.0  1.0  1.0  0.0\n",
      "5    strsim:1_emb:-1_eq:2     1.0   1.0  1.0  1.0  0.0\n",
      "7     strsim:1_emb:2_eq:3     1.0   1.0  1.0  1.0  0.0\n",
      "9    strsim:2_emb:-1_eq:1     1.0   1.0  1.0  1.0  0.0\n",
      "10   strsim:2_emb:1_eq:-1     1.0   1.0  1.0  1.0  0.0\n",
      "11    strsim:2_emb:1_eq:3     1.0   1.0  1.0  1.0  0.0\n",
      "13    strsim:3_emb:1_eq:2     1.0   1.0  1.0  1.0  0.0\n",
      "14    strsim:3_emb:2_eq:1     1.0   1.0  1.0  1.0  0.0\n"
     ]
    }
   ],
   "source": [
    "print('Aggregates')\n",
    "for file in files:\n",
    "    datasetname = file.split('_')[0]\n",
    "    datasetname = file.split('/')[-1].split('_')[0]\n",
    "    print(f'Analyzing {datasetname}')\n",
    "    df = pd.read_csv(file)\n",
    "    # print(df.head())\n",
    "\n",
    "\n",
    "    df['method_strategy'] = (\n",
    "        'strsim:' + df['strsim'].astype(str) +\n",
    "        '_emb:' + df['emebedding'].astype(str) +\n",
    "        '_eq:' + df['equal'].astype(str)\n",
    "    )\n",
    "\n",
    "\n",
    "    df_grouped = best_aggregate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
